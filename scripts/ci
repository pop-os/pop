#!/usr/bin/env python3

# Setting up sbuild requires the following commands:
#     sudo apt install sbuild
#     sudo sbuild-adduser "$USER"
#     newgrp sbuild
#     ./scripts/schroot

import argparse
from collections import namedtuple
from debian.changelog import Changelog, Version
from debian.deb822 import Dsc, Deb822
import multiprocessing
import os
from os import path
import pathlib
import shutil
from subprocess import check_call, check_output
import sys
from threading import Lock

from lib import foreach_repo_parallel, github_post
from git import git_ids_and_branches, git_timestamp_id, git_datetime_id, git_archive_id

Series = namedtuple('Series', 'codename version')

parser = argparse.ArgumentParser(description="Package and deploy all Pop!_OS repositories")
parser.add_argument("repos", nargs="*", default=[])
parser.add_argument("--dev", action="store_true")
parser.add_argument("--retry", type=lambda s: s.split())
args = parser.parse_args(sys.argv[1:])

if args.retry is None:
    args.retry = []

POP_DIR = path.dirname(path.dirname(path.abspath(__file__)))
if args.dev:
    BUILD_DIR = path.join(POP_DIR, '_build', 'dev')
    os.environ["S76_DEV"] = "1"
else:
    BUILD_DIR = path.join(POP_DIR, '_build')
GIT_DIR = path.join(BUILD_DIR, 'git')
SOURCE_DIR = path.join(BUILD_DIR, 'source')
BINARY_DIR = path.join(BUILD_DIR, 'binary')
REPO_DIR = path.join(BUILD_DIR, 'repos')
FAILURES_DIR = path.join(BUILD_DIR, 'failures')

# Architectures to build for
build_archs = {
    'amd64': True,
    'i386': False,
}

build_series = {
    'bionic': ('18.04', True),
    'focal': ('20.04', True),
    'groovy': ('20.10', True),
    'hirsute': ('21.04', True),
}

def iprint(level, value):
    indent = ' ' * (level * 4)
    print('>>> ' + indent + str(value), flush=True)

def parse_branch(branch):
    parts = branch.split('_')
    assert len(parts) <= 2
    pocket = parts[0]
    codename = (None if len(parts) < 2 else parts[1])
    return (pocket, codename)

def iter_series(branches):
    for b in branches:
        if '/' in b:
            continue
        (pocket, codename) = parse_branch(b)
        if codename is None:
            for (codename, (version, wildcard)) in build_series.items():
                if wildcard:
                    yield (Series(codename, version), (pocket, True))
        elif codename in build_series:
            version, wildcard = build_series[codename]
            yield (Series(codename, version), (pocket, False))

def expand_series(branches):
    result = {}
    for (series, (pocket, wildcard)) in iter_series(branches):
        if series not in result:
            result[series] = set()
        result[series].add((pocket, wildcard))
    return result

GitTar = namedtuple('GitTar', 'id timestamp datetime archive')

def git_tar(cwd, _id):
    timestamp = git_timestamp_id(cwd, _id)
    datetime = git_datetime_id(cwd, _id)
    archive = path.join(GIT_DIR, _id + ".tar")
    if path.exists(archive):
        print("\x1B[1m{} commit {}: git already built\x1B[0m".format(path.basename(cwd), _id), flush=True)
    else:
        print("\x1B[1m{} commit {}: building git\x1B[0m".format(path.basename(cwd), _id), flush=True)
        git_archive_id(cwd, _id, archive)
        print("\x1B[1m{} commit {}: finished building git\x1B[0m".format(path.basename(cwd), _id), flush=True)
    return GitTar(_id, timestamp, datetime, archive)

def github_status(name, _id, context, state):
    target_url = os.environ.get("BUILD_URL")
    if target_url is None:
        return
    else:
        print("\x1B[1m{} commit {}: setting github status of {} to {}\x1B[0m".format(name, _id, context, state), flush=True)

    url = "https://api.github.com/repos/pop-os/" + name + "/statuses/" + _id

    if args.dev:
        data = {
            "context": "ubuntu/staging/" + context,
            "description": "Ubuntu Staging " + context,
            "state": state,
            "target_url": target_url
        }
    else:
        data = {
            "context": "pop-os/staging/" + context,
            "description": "Pop!_OS Staging " + context,
            "state": state,
            "target_url": target_url
        }

    response = github_post(url, data)

    return response

debuild_lock = Lock()

def dpkg_source(name, git, series):
    extract_dir = path.join(SOURCE_DIR, git.id + "_" + series.codename)

    if path.isdir(extract_dir):
        shutil.rmtree(extract_dir)

    os.mkdir(extract_dir)

    check_call(['tar', 'xf', git.archive], cwd=extract_dir)

    debian_path = path.join(extract_dir, 'debian')
    if not path.isdir(debian_path):
         print("\x1B[1m{} commit {} on {}: no debian dir\x1B[0m".format(name, git.id, series.codename), flush=True)
         return None, None

    control_path = path.join(debian_path, "control")
    with open(control_path, "r") as fp:
        control = Deb822(fp)

    o = check_output(["dpkg-parsechangelog", "--show-field", "Version"], cwd=extract_dir)
    changelog_version = o.decode().strip()

    source_name = control.get("Source")
    if series.codename in ('xenial', 'artful'):
        # Old format, caused issues when adding debian versions like 0.2.8 -> 0.2.8-1
        version = '+'.join([changelog_version, git.timestamp, series.version]) + "~" + git.id[:7]
    elif args.dev:
        # New format, will allow debian versions to be added
        version = '~'.join([changelog_version, git.timestamp, series.version, git.id[:7], "dev"])
    else:
        # New format, will allow debian versions to be added
        version = '~'.join([changelog_version, git.timestamp, series.version, git.id[:7]])

    path_version = version.split(":", 1)[-1]

    dsc_path = path.join(SOURCE_DIR, source_name + "_" + path_version + ".dsc")
    tar_path = path.join(SOURCE_DIR, source_name + "_" + path_version + ".tar.xz")

    if not os.path.exists(dsc_path) or not os.path.exists(tar_path):
        print("\x1B[1m{} commit {} on {}: building source\x1B[0m".format(source_name, git.id, series.codename), flush=True)

        try:
            github_status(name, git.id, series.codename + "/source", "pending")

            if name == "linux":
                # If building Linux, copy debian.master changelog
                changelog_path = path.join(extract_dir, 'debian.master', 'changelog')
                with open(changelog_path, 'r') as f:
                     changelog = Changelog(f.read())
            else:
                changelog_path = path.join(debian_path, 'changelog')
                changelog = Changelog()
                changelog.new_block()

            # Update latest block
            changelog.set_package(source_name)
            changelog.set_version(Version(version))
            changelog.set_distributions(series.codename)
            changelog.set_urgency("medium")
            changelog.set_author(os.environ["DEBFULLNAME"] + " <" + os.environ["DEBEMAIL"] + ">")
            changelog.set_date(git.datetime)
            changelog.add_change('')
            changelog.add_change('  * Auto Build')
            changelog.add_change('')

            # Save updated changelog
            with open(changelog_path, 'w') as f:
                changelog.write_to_open_file(f)

            if os.path.exists(path.join(debian_path, 'patches')):
                print("\x1B[1m{} commit {} on {}: applying debian patches\x1B[0m".format(source_name, git.id, series.codename), flush=True)

                with open(os.devnull, 'w') as null:
                    check_call([
                        'quilt',
                        'push',
                        '-a',
                    ], stdout=null, cwd=extract_dir, env={"QUILT_PATCHES": "debian/patches"})

                print("\x1B[1m{} commit {} on {}: finished applying debian patches\x1B[0m".format(source_name, git.id, series.codename), flush=True)

            if name == "linux":
                print("\x1B[1m{} commit {} on {}: updating changelog\x1B[0m".format(source_name, git.id, series.codename), flush=True)

                with open(os.devnull, 'w') as null:
                    check_call([
                        "fakeroot",
                        "debian/rules",
                        "clean"
                    ], stdout=null, cwd=extract_dir)

                print("\x1B[1m{} commit {} on {}: finished updating changelog\x1B[0m".format(source_name, git.id, series.codename), flush=True)

            with debuild_lock:
                with open(os.devnull, 'w') as null:
                    check_call([
                        'debuild',
                        '--preserve-envvar', 'PATH',
                        '--set-envvar', 'SOURCE_DATE_EPOCH=' + str(git.timestamp),
                        '--no-tgz-check',
                        '-d',
                        '-S',
                        '--source-option=--tar-ignore=.git',
                    ], stdout=null, stderr=null, cwd=extract_dir)

            print("\x1B[1m{} commit {} on {}: finished building source\x1B[0m".format(source_name, git.id, series.codename), flush=True)

            github_status(name, git.id, series.codename + "/source", "success")
        except Exception as ex:
            message = "\x1B[1m{} commit {} on {}: failed to build source: {!r}\x1B[0m\n".format(source_name, git.id, series.codename, ex)

            build_log_filename = source_name + "_" + path_version + "_source.build"
            build_log = path.join(SOURCE_DIR, build_log_filename)
            failure_build_log = path.join(FAILURES_DIR, build_log_filename)
            if path.exists(build_log):
                shutil.copyfile(build_log, failure_build_log)

                with open(build_log, 'r') as f:
                    message += f.read()

            print(message, flush=True)

            try:
                github_status(name, git.id, series.codename + "/source", "failure")
            except Exception as ex_s:
                print("\x1B[1m{} commit {} on {}: failed to report build failure: {!r}\x1B[0m\n".format(source_name, git.id, series.codename, ex_s))

            return None, None
    else:
        print("\x1B[1m{} commit {} on {}: source already built\x1B[0m".format(source_name, git.id, series.codename), flush=True)

    if not path.exists(dsc_path):
        print("\x1B[1m{} commit {} on {}: missing dsc {}\x1B[0m".format(source_name, git.id, series.codename, dsc_path), flush=True)
        return None, None

    if not path.exists(tar_path):
        print("\x1B[1m{} commit {} on {}: missing tar {}\x1B[0m".format(source_name, git.id, series.codename, tar_path), flush=True)
        return None, None

    return dsc_path, tar_path

def dpkg_binary(dsc_path, name, git, series, build_arch, build_all):
    with open(dsc_path, "r") as fp:
        dsc = Dsc(fp)

    source_name = dsc.get("Source")
    version = dsc.get("Version")
    package_list = dsc.get("Package-List")

    path_version = version.split(":", 1)[-1]

    found_binaries = True
    debs = []
    for package_line in package_list.strip().split("\n"):
        parts = package_line.strip().split(" ")
        binary = parts[0]
        kind = parts[1]
        if kind in ["udeb"]:
            # Ignore udebs
            continue
        for arch in parts[4].replace("arch=", "").split(","):
            if arch == "any" or arch == "linux-any" or arch == build_arch:
                deb_arch = build_arch
            elif arch == "all" and build_all:
                deb_arch = "all"
            else:
                continue
            if name == "linux":
                # If building Linux, some packages that are not required
                if (
                    binary.endswith("-dbgsym") or
                    binary.startswith("linux-udebs-")
                ):
                    continue
                # Check for alt version used by meta packages
                alt_version = path_version.replace("-", ".", 1)
                alt_path = path.join(BINARY_DIR, binary + "_" + alt_version + "_" + deb_arch + ".deb")
                if path.exists(alt_path):
                    debs.append(alt_path)
                    continue
            if name == "systemd" and binary.endswith("-udeb"):
                # If building systemd, some packages are not required
                continue
            deb_path = path.join(BINARY_DIR, binary + "_" + path_version + "_" + deb_arch + ".deb")
            debs.append(deb_path)
            if not path.exists(deb_path):
                found_binaries = False
    if not debs:
        return []

    build_log_filename = source_name + "_" + path_version + "_" + build_arch + ".build"
    build_log = path.join(BINARY_DIR, build_log_filename)
    failure_build_log = path.join(FAILURES_DIR, build_log_filename)

    retry_keys = [
        name,
        'source:' + source_name,
        'git:' + git.id,
        'dist:' + series.codename,
        'arch:' + build_arch,
    ]

    retry = False
    for retry_key in retry_keys:
        if args.retry.contains(retry_key):
            retry = True

    if found_binaries:
        print("\x1B[1m{} commit {} on {}: binaries for {} already built\x1B[0m".format(source_name, git.id, series.codename, build_arch), flush=True)
    elif not path.exists(build_log) or retry:
        print("\x1B[1m{} commit {} on {}: building binaries for {}\x1B[0m".format(source_name, git.id, series.codename, build_arch), flush=True)

        try:
            github_status(name, git.id, series.codename + "/binary-" + build_arch, "pending")

            if args.dev:
                ppa_key = ".ppa-dev.asc"
                ppa_release = "system76-dev/stable"
                ppa_proposed = "system76-dev/pre-stable"
            else:
                ppa_key = ".ppa.asc"
                ppa_release = "system76/pop"
                ppa_proposed = "system76/proposed"

            sbuild = [
                "sbuild",
                "--arch=" + build_arch,
                "--dist=" + series.codename,
                "--quiet",
                "--extra-repository=deb http://us.archive.ubuntu.com/ubuntu/ " + series.codename + "-updates main restricted universe multiverse",
                "--extra-repository=deb-src http://us.archive.ubuntu.com/ubuntu/ " + series.codename + "-updates main restricted universe multiverse",
                "--extra-repository=deb http://us.archive.ubuntu.com/ubuntu/ " + series.codename + "-security main restricted universe multiverse",
                "--extra-repository=deb-src http://us.archive.ubuntu.com/ubuntu/ " + series.codename + "-security main restricted universe multiverse",
                "--extra-repository=deb http://ppa.launchpad.net/" + ppa_release + "/ubuntu " + series.codename + " main",
                "--extra-repository=deb-src http://ppa.launchpad.net/" + ppa_release + "/ubuntu " + series.codename + " main",
                "--extra-repository=deb http://ppa.launchpad.net/" + ppa_proposed + "/ubuntu " + series.codename + " main",
                "--extra-repository=deb-src http://ppa.launchpad.net/" + ppa_proposed + "/ubuntu " + series.codename + " main",
                "--extra-repository-key=" + path.join(POP_DIR, "scripts", ppa_key),
                "--no-apt-distupgrade",
            ]

            if build_all:
                sbuild.append("--arch-all")

            sbuild.append(dsc_path)

            check_call(sbuild, cwd=BINARY_DIR)

            print("\x1B[1m{} commit {} on {}: finished building binaries\x1B[0m".format(source_name, git.id, series.codename), flush=True)

            github_status(name, git.id, series.codename + "/binary-" + build_arch, "success")
        except Exception as ex:
            try:
                github_status(name, git.id, series.codename + "/binary-" + build_arch, "failure")
            except Exception as ex_s:
                print("\x1B[1m{} commit {} on {}: failed to report build failure: {!r}\x1B[0m\n".format(source_name, git.id, series.codename, ex_s))

            if path.exists(build_log):
                shutil.copyfile(build_log, failure_build_log)

                with open(build_log, 'rb') as f:
                    sys.stdout.buffer.write(f.read())
            else:
                print("\x1B[1m{} commit {} on {}: failed to find build log: {!r}\x1B[0m\n".format(source_name, git.id, series.codename, build_log))

            print("\x1B[1m{} commit {} on {}: failed to build binaries: {!r}\x1B[0m\n".format(source_name, git.id, series.codename, ex), flush=True)

            return []
    else:
        if path.exists(build_log):
            shutil.copyfile(build_log, failure_build_log)

        print("\x1B[1m{} commit {} on {}: binaries already failed to build\x1B[0m".format(source_name, git.id, series.codename), flush=True)

    for deb_path in debs:
        if not path.exists(deb_path):
            print("\x1B[1m{} commit {} on {}: missing binary {}\x1B[0m".format(source_name, git.id, series.codename, deb_path), flush=True)
            return []

    return debs

def build_packages_thread(args):
    name, git, series, pockets = args
    dsc_path, tar_path = dpkg_source(name, git, series)
    deb_paths = []
    if dsc_path and tar_path:
        for build_arch in build_archs:
            build_all = build_archs[build_arch]
            deb_paths += dpkg_binary(dsc_path, name, git, series, build_arch, build_all)
    return (name, git, series, pockets, dsc_path, tar_path, deb_paths)

def build_packages(name):
    cwd = path.join(POP_DIR, name)

    if not path.exists(cwd):
        print('\x1B[1m{}: did not find {!r}\x1B[0m'.format(name, cwd), flush=True)
        return {}

    # Remove conflicting wildcards
    pocket_series_ids = {}
    ids = git_ids_and_branches(cwd)
    for (_id, branches) in sorted(ids.items()):
        expanded = expand_series(branches)
        for (series, pockets) in sorted(expanded.items()):
            for (pocket, wildcard) in pockets:
                if not pocket in pocket_series_ids:
                    pocket_series_ids[pocket] = {}
                if not wildcard or not series in pocket_series_ids[pocket]:
                    pocket_series_ids[pocket][series] = _id

    sources = []
    ids = git_ids_and_branches(cwd)
    for (_id, branches) in sorted(ids.items()):
        git = git_tar(cwd, _id)
        expanded = expand_series(branches)
        for (series, pockets) in sorted(expanded.items()):
            skip = True
            for (pocket, wildcard) in pockets:
                if pocket_series_ids[pocket][series] == _id:
                    skip = False
            if skip:
                continue
            sources.append((name, git, series, pockets))

    mp_pool = multiprocessing.pool.ThreadPool()
    binaries = mp_pool.map(build_packages_thread, sources)
    mp_pool.close()
    mp_pool.join()

    pocket_series = {}
    for _name, _git, series, pockets, dsc_path, tar_path, deb_paths in binaries:
        if dsc_path and tar_path and deb_paths:
            for (pocket, wildcard) in sorted(pockets):
                if not pocket in pocket_series:
                    pocket_series[pocket] = []

                if not series in pocket_series[pocket]:
                    pocket_series[pocket].append(series)

                # Produce pool: http://ppa.launchpad.net/system76/pop/ubuntu/pool/
                pool_dir = path.join(REPO_DIR, pocket, "pool", series.codename, name)
                pathlib.Path(pool_dir).mkdir(parents=True, exist_ok=True)

                dsc_dst = path.join(pool_dir, path.basename(dsc_path))
                if not path.exists(dsc_dst):
                    os.link(dsc_path, dsc_dst)

                tar_dst = path.join(pool_dir, path.basename(tar_path))
                if not path.exists(tar_dst):
                    os.link(tar_path, tar_dst)

                for deb_path in deb_paths:
                    deb_dst = path.join(pool_dir, path.basename(deb_path))
                    if not path.exists(deb_dst):
                        os.link(deb_path, deb_dst)

    return pocket_series

def create_dist(email, pocket, series):
    pocket_dir = path.join(REPO_DIR, pocket)

    dist_dir = path.join(pocket_dir, "dists", series.codename)
    os.makedirs(dist_dir)

    comp_dir = path.join(dist_dir, "main")
    os.mkdir(comp_dir)

    source_dir = path.join(comp_dir, "source")
    os.mkdir(source_dir)

    # Generate source directory: http://ppa.launchpad.net/system76/pop/ubuntu/dists/artful/main/source/
    source = check_output([
        "apt-ftparchive", "-qq",
        "sources", path.join("pool", series.codename)
    ], cwd=pocket_dir).decode()

    with open(path.join(source_dir, "Sources"), "w") as f:
        f.write(source)

    check_call(["gzip", "--keep", path.join(source_dir, "Sources")])

    # Example source release file: http://ppa.launchpad.net/system76/pop/ubuntu/dists/artful/main/source/Release
    with open(path.join(source_dir, "Release"), "w") as f:
        f.write("Archive: " + series.codename + "\n")
        f.write("Version: " + series.version + "\n")
        f.write("Component: main\n")
        f.write("Origin: pop-os-staging-" + pocket + "\n")
        f.write("Label: Pop!_OS Staging " + pocket + "\n")
        f.write("Architecture: source\n")

    for build_arch in build_archs:
        binary_dir = path.join(comp_dir, "binary-" + build_arch)
        os.mkdir(binary_dir)

        # Generate binary directory: http://ppa.launchpad.net/system76/pop/ubuntu/dists/artful/main/binary-amd64/
        packages = check_output([
            "apt-ftparchive",
            "--arch", build_arch,
            "packages", path.join("pool", series.codename)
        ], cwd=pocket_dir).decode()

        with open(path.join(binary_dir, "Packages"), "w") as f:
            f.write(packages)

        check_call(["gzip", "--keep", path.join(binary_dir, "Packages")])

        # Example binary release file: http://ppa.launchpad.net/system76/pop/ubuntu/dists/artful/main/binary-amd64/Release
        with open(path.join(binary_dir, "Release"), "w") as f:
            f.write("Archive: " + series.codename + "\n")
            f.write("Version: " + series.version + "\n")
            f.write("Component: main\n")
            f.write("Origin: pop-os-staging-" + pocket + "\n")
            f.write("Label: Pop!_OS Staging " + pocket + "\n")
            f.write("Architecture: " + build_arch + "\n")

    # Example dists release file: http://ppa.launchpad.net/system76/pop/ubuntu/dists/artful/Release
    release = check_output([
        "apt-ftparchive",
        "-o", "APT::FTPArchive::Release::Origin=pop-os-staging-" + pocket,
        "-o", "APT::FTPArchive::Release::Label=Pop!_OS Staging " + pocket,
        "-o", "APT::FTPArchive::Release::Suite=" + series.codename,
        "-o", "APT::FTPArchive::Release::Version=" + series.version,
        "-o", "APT::FTPArchive::Release::Codename=" + series.codename,
        "-o", "APT::FTPArchive::Release::Architectures=" + " ".join(build_archs.keys()),
        "-o", "APT::FTPArchive::Release::Components=main",
        "-o", "APT::FTPArchive::Release::Description=Pop!_OS Staging " + series.codename + " " + series.version + " " + pocket,
        "release", "."
    ], cwd=dist_dir).decode()

    with open(path.join(dist_dir, "Release"), "w") as f:
        f.write(release)

    check_call([
        "gpg", "--clearsign",
        "--local-user", email,
        "--batch", "--yes",
        "--digest-algo", "sha512",
        "-o", path.join(dist_dir, "InRelease"), path.join(dist_dir, "Release")
    ])

    check_call([
        "gpg", "-abs",
        "--local-user", email,
        "--batch", "--yes",
        "--digest-algo", "sha512",
        "-o", path.join(dist_dir, "Release.gpg"), path.join(dist_dir, "Release")
    ])

def create_dists(email, pocket_series):
    for pocket in pocket_series:
        iprint(0, pocket)

        for series in pocket_series[pocket]:
            iprint(1, series)

            create_dist(email, pocket, series)

def callback(repo):
    name =  repo['name']

    if name.startswith("packaging-"):
        print('\x1B[1m{}: skipping\x1B[0m'.format(name), flush=True)
        return {}
    else:
        return build_packages(name)

def create_dir(d):
    if not path.isdir(d):
        os.mkdir(d)

def recreate_dir(d):
    if path.isdir(d):
        shutil.rmtree(d)
        os.mkdir(d)

def ci():
    email = os.environ.get("DEBEMAIL")
    if email is None:
        raise Exception("DEBEMAIL is not set")

    full_name = os.environ.get("DEBFULLNAME")
    if full_name is None:
        raise Exception("DEBFULLNAME is not set")

    create_dir(BUILD_DIR)

    create_dir(GIT_DIR)
    create_dir(SOURCE_DIR)
    create_dir(BINARY_DIR)
    recreate_dir(REPO_DIR)

    if path.isdir(FAILURES_DIR):
        shutil.rmtree(FAILURES_DIR)
    os.mkdir(FAILURES_DIR)

    all_pocket_series = {}
    for repo_name, pocket_series in foreach_repo_parallel(callback, args.repos, args.dev, 4).items():
        for pocket in pocket_series:
            for series in pocket_series[pocket]:
                if not pocket in all_pocket_series:
                    all_pocket_series[pocket] = []

                if not series in all_pocket_series[pocket]:
                    all_pocket_series[pocket].append(series)

    create_dists(email, all_pocket_series)

ci()
